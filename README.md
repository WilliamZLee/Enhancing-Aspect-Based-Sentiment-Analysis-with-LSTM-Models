# Enhancing-Aspect-Based-Sentiment-Analysis-with-LSTM-Models

# Project Overview
This project focuses on enhancing LSTM-based models for Aspect-Based Sentiment Analysis (ABSA) using various configurations and optimizations. We incorporate pre-trained embeddings (Word2Vec and GloVe) and attention mechanisms to improve the performance and interpretability of the models. The main goal is to achieve high accuracy in sentiment classification by optimizing the model's architecture and hyperparameters.

# Team Members
Liweiwen Zhou: Responsible for model training and debugging.
Zirui Xiong: Responsible for data preprocessing, hyperparameter tuning, and literature review.
Both: Contributed to coding, debugging, and final report writing.

# Results
Our experiments show that the LSTM model with Word2Vec embeddings and optimized hyperparameters achieved the best performance. We observed significant improvements in accuracy and recall when using the A100 GPU compared to the RTX4060.

# Acknowledgements
We thank the authors of the pre-trained Word2Vec and GloVe embeddings for providing the resources used in this project.

# Contact
For any questions or inquiries, please contact:

Liweiwen Zhou: 24100792@student.uwa.edu.au
Zirui Xiong: 24140167@student.uwa.edu.au
We hope this project helps in understanding and improving Aspect-Based Sentiment Analysis using LSTM models and pre-trained embeddings.
