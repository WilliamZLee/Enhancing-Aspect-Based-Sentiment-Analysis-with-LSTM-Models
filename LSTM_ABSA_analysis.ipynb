{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 2024 CITS4012 Project"
      ],
      "metadata": {
        "id": "m9aa7lcbYKxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Group 38**\n",
        "\n",
        "\n",
        "Liweiwen Zhou 24100792\n",
        "Zirui Xiong 24140167\n",
        "\n",
        "The Project has been uploaded to Github, for test running please refer to:\n",
        "https://github.com/WilliamZLee/Enhancing-Aspect-Based-Sentiment-Analysis-with-LSTM-Models"
      ],
      "metadata": {
        "id": "oLFxl3VHZEeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Environment set, package import**"
      ],
      "metadata": {
        "id": "nwSbAxwHlxk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! /opt/bin/nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUk_uxH577-l",
        "outputId": "8960444d-a3dc-4941-e0f6-9bf81b6a44fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun May 19 18:50:17 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0              44W / 400W |      2MiB / 40960MiB |      0%      Default |\n",
            "|                                         |                      |             Disabled |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMYENzgv78gM",
        "outputId": "a4bd06ac-7f1f-45ee-93a8-ff2387424135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks\n",
        "!ls"
      ],
      "metadata": {
        "id": "TOk-yGda8Kac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c43b6025-6708-4c87-8a06-d302329f9848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n",
            " “CITS4012_Lab01.ipynb”的副本\t     “CITS4012_Lab07.ipynb”的副本   test.json\n",
            "'“CITS4012_Lab01.ipynb”的副本 (1)'   “CITS4012_Lab08.ipynb”的副本   train.json\n",
            " “CITS4012_Lab02.ipynb”的副本\t     “CITS4012_Lab09.ipynb”的副本   Untitled0.ipynb\n",
            " “CITS4012_Lab03.ipynb”的副本\t     “CITS4012_Lab10.ipynb”的副本   Untitled1.ipynb\n",
            " “CITS4012_Lab04.ipynb”的副本\t     cuhk_sysu.zip\t\t    Untitled2.ipynb\n",
            " “CITS4012_Lab05.ipynb”的副本\t     exp_cuhk.zip\t\t    val.json\n",
            " “CITS4012_Lab06.ipynb”的副本\t     exp_prw.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yJ1SdEE-Oci",
        "outputId": "5f1c91a6-5a33-4e1c-828e-2e19762ab759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVVPbS3hX0D4",
        "outputId": "d80c05c3-e8b4-4849-ad9a-c2d9e6567991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.6.6)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.10)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.1.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.20.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.2.1)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.2.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.1.5)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (24.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.19.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.19.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.18.1)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.2.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.22)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wH1ZgVhDyX9",
        "outputId": "5feeeeb8-90d2-4ac9-e43a-127d9c89b996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "import os\n",
        "import gensim.downloader as api\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin"
      ],
      "metadata": {
        "id": "D2PF16bC9Xz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import torch\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "qB1YMAwTgiI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets"
      ],
      "metadata": {
        "id": "weswB1ZkX4Z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = os.path.expanduser(\"~/.cache/gensim/word2vec-google-news-300\")\n",
        "\n",
        "\n",
        "if os.path.exists(model_dir):\n",
        "    print(\"Word2Vec is downloaded to local env\")\n",
        "else:\n",
        "    print(\"Word2Vec is not downloaded to local env, downloading...\")\n",
        "    word2vec_model = api.load('word2vec-google-news-300')\n",
        "    print(\"download complete\")\n",
        "\n",
        "\n",
        "word2vec_model = api.load('word2vec-google-news-300')\n",
        "print(\"Word2Vec model successfuly loaded\")\n",
        "\n",
        "\n",
        "print(f\"model contains {len(word2vec_model.key_to_index)} words\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FQNVchFMi2F",
        "outputId": "9dcb6b9b-9d8d-4d08-9913-77b45f5888e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec is not downloaded to local env, downloading...\n",
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "download complete\n",
            "Word2Vec model successfuly loaded\n",
            "model contains 3000000 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.Dataset Processing**"
      ],
      "metadata": {
        "id": "J_J8w26bl4_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "def load_data(file_path):\n",
        "    data = pd.read_json(file_path, lines=True)\n",
        "    data = pd.DataFrame(data['data'][0], columns=data['columns'][0])\n",
        "    return data\n",
        "\n",
        "# Build vocabulary and index mappings\n",
        "def build_vocab_and_mappings(data):\n",
        "    all_reviews = data['sentence'].tolist()\n",
        "    all_tokens = [token for review in all_reviews for token in word_tokenize(review)]\n",
        "    vocab = list(set(all_tokens))\n",
        "    word_to_idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "    aspect_to_idx = {aspect: idx for idx, aspect in enumerate(set(data['aspect'].tolist()))}\n",
        "    sentiment_to_idx = {'positive': 0, 'negative': 1, 'neutral': 2}\n",
        "    return vocab, word_to_idx, aspect_to_idx, sentiment_to_idx\n"
      ],
      "metadata": {
        "id": "Ayd9u7oyBupy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load Word2Vec embeddings\n",
        "def load_word2vec_embeddings(word2vec_model, word_to_idx, embedding_dim=300):\n",
        "    embeddings_index = {}\n",
        "    for word in word2vec_model.key_to_index:\n",
        "        embeddings_index[word] = word2vec_model[word]\n",
        "\n",
        "    embedding_matrix = np.zeros((len(word_to_idx), embedding_dim))\n",
        "    for word, idx in word_to_idx.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[idx] = embedding_vector\n",
        "    return embedding_matrix"
      ],
      "metadata": {
        "id": "mTBUWCQjBxUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load GloVe embeddings\n",
        "def load_glove_embeddings(glove_file_path, word_to_idx, embedding_dim=300):\n",
        "    embeddings_index = {}\n",
        "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "\n",
        "    embedding_matrix = np.zeros((len(word_to_idx), embedding_dim))\n",
        "    for word, idx in word_to_idx.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[idx] = embedding_vector\n",
        "    return embedding_matrix\n"
      ],
      "metadata": {
        "id": "CFKdKSaFByjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "def preprocess_data(df, word_to_idx, aspect_to_idx, sentiment_to_idx):\n",
        "    reviews = [torch.tensor([word_to_idx.get(token, 0) for token in word_tokenize(review)], dtype=torch.long) for review in df['sentence']]\n",
        "    aspects = torch.tensor([aspect_to_idx[aspect] for aspect in df['aspect']], dtype=torch.long)\n",
        "    sentiments = torch.tensor([sentiment_to_idx[sentiment] for sentiment in df['polarity']], dtype=torch.long)\n",
        "    return reviews, aspects, sentiments\n",
        "\n",
        "# ABSA Dataset\n",
        "class ABSA_Dataset(Dataset):\n",
        "    def __init__(self, reviews, aspects, sentiments):\n",
        "        self.reviews = reviews\n",
        "        self.aspects = aspects\n",
        "        self.sentiments = sentiments\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.reviews)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.reviews[idx], self.aspects[idx], self.sentiments[idx]\n",
        "\n",
        "# Collate function\n",
        "def collate_fn(batch):\n",
        "    reviews, aspects, sentiments = zip(*batch)\n",
        "    reviews_padded = torch.nn.utils.rnn.pad_sequence(reviews, batch_first=True, padding_value=0)\n",
        "    aspects = torch.tensor(aspects)\n",
        "    sentiments = torch.tensor(sentiments)\n",
        "    return reviews_padded, aspects, sentiments"
      ],
      "metadata": {
        "id": "nB0b2_By9vZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Basic LSTM, with Glove and advanced**"
      ],
      "metadata": {
        "id": "flti4PNYkfid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM BASIC\n",
        "class BasicLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, aspect_dim, dropout=0.5,embedding_matrix = None):\n",
        "        super(BasicLSTM, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.aspect_embedding = nn.Embedding(len(aspect_to_idx), aspect_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim + aspect_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, reviews, aspects):\n",
        "        embedded_reviews = self.embedding(reviews)\n",
        "        embedded_aspects = self.aspect_embedding(aspects).unsqueeze(1).repeat(1, embedded_reviews.size(1), 1)\n",
        "        lstm_input = torch.cat((embedded_reviews, embedded_aspects), dim=2)\n",
        "        lstm_output, _ = self.lstm(lstm_input)\n",
        "        final_feature_map = self.dropout(lstm_output[:, -1, :])\n",
        "        output = self.fc(final_feature_map)\n",
        "        return output"
      ],
      "metadata": {
        "id": "E1P4KydikYQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM WITH GloVe only\n",
        "class GloVeLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, aspect_dim, dropout=0.5, embedding_matrix=None):\n",
        "        super(GloVeLSTM, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        if embedding_matrix is not None:\n",
        "            self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "            self.embedding.weight.requires_grad = False\n",
        "        self.aspect_embedding = nn.Embedding(len(aspect_to_idx), aspect_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim + aspect_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, reviews, aspects):\n",
        "        embedded_reviews = self.embedding(reviews)\n",
        "        embedded_aspects = self.aspect_embedding(aspects).unsqueeze(1).repeat(1, embedded_reviews.size(1), 1)\n",
        "        lstm_input = torch.cat((embedded_reviews, embedded_aspects), dim=2)\n",
        "        lstm_output, _ = self.lstm(lstm_input)\n",
        "        final_feature_map = self.dropout(lstm_output[:, -1, :])\n",
        "        output = self.fc(final_feature_map)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "XujLmt-AkYGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM with GloVe and advanced optimize\n",
        "class AdvancedGloVeLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, aspect_dim, dropout=0.5, embedding_matrix=True):\n",
        "        super(AdvancedGloVeLSTM, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        if embedding_matrix is not None:\n",
        "            self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "            self.embedding.weight.requires_grad = True  # Allow training embeddings\n",
        "        self.aspect_embedding = nn.Embedding(len(aspect_to_idx), aspect_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim + aspect_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, reviews, aspects):\n",
        "        embedded_reviews = self.embedding(reviews)\n",
        "        embedded_aspects = self.aspect_embedding(aspects).unsqueeze(1).repeat(1, embedded_reviews.size(1), 1)\n",
        "        lstm_input = torch.cat((embedded_reviews, embedded_aspects), dim=2)\n",
        "        lstm_output, _ = self.lstm(lstm_input)\n",
        "        final_feature_map = self.dropout(lstm_output[:, -1, :])\n",
        "        output = self.fc(final_feature_map)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "UI3HoMwhkYAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function with early stopping, learning rate scheduler, and gradient clipping\n",
        "def train_model(model, train_loader, val_loader, epochs, learning_rate, patience, weight_decay, clip_value):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5, verbose=True)\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for reviews, aspects, sentiments in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(reviews, aspects)\n",
        "            loss = criterion(outputs, sentiments)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for reviews, aspects, sentiments in val_loader:\n",
        "                outputs = model(reviews, aspects)\n",
        "                loss = criterion(outputs, sentiments)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        scheduler.step(val_loss)\n",
        "        print(f'Epoch {epoch+1}, Training Loss: {total_loss / len(train_loader)}, Validation Loss: {val_loss}')\n",
        "\n",
        "        # Early stopping logic\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered\")\n",
        "                break"
      ],
      "metadata": {
        "id": "yfhjrrm7kX4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F66UIbzlYpLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Load and preprocess data\n",
        "    train_data = load_data('train.json')\n",
        "    val_data = load_data('val.json')\n",
        "    test_data = load_data('test.json')\n",
        "\n",
        "    vocab, word_to_idx, aspect_to_idx, sentiment_to_idx = build_vocab_and_mappings(pd.concat([train_data, val_data, test_data]))\n",
        "\n",
        "    train_reviews, train_aspects, train_sentiments = preprocess_data(train_data, word_to_idx, aspect_to_idx, sentiment_to_idx)\n",
        "    val_reviews, val_aspects, val_sentiments = preprocess_data(val_data, word_to_idx, aspect_to_idx, sentiment_to_idx)\n",
        "    test_reviews, test_aspects, test_sentiments = preprocess_data(test_data, word_to_idx, aspect_to_idx, sentiment_to_idx)\n",
        "\n",
        "    # Load GloVe embeddings\n",
        "    embedding_matrix = load_glove_embeddings('glove.6B.300d.txt', word_to_idx) if use_glove else None\n",
        "\n",
        "    # Initialize datasets and data loaders\n",
        "    train_dataset = ABSA_Dataset(train_reviews, train_aspects, train_sentiments)\n",
        "    val_dataset = ABSA_Dataset(val_reviews, val_aspects, val_sentiments)\n",
        "    test_dataset = ABSA_Dataset(test_reviews, test_aspects, test_sentiments)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    # Define and train models for each stage\n",
        "    for stage, ModelClass in zip([\"Basic\", \"GloVe\", \"AdvancedGloVe\"], [BasicLSTM, GloVeLSTM, AdvancedGloVeLSTM]):\n",
        "        print(f\"Training {stage} Model\")\n",
        "        model = ModelClass(len(vocab), 300, 128, 3, len(aspect_to_idx), embedding_matrix=embedding_matrix)\n",
        "        train_model(model, train_loader, val_loader, epochs=10, learning_rate=0.001, patience=3, weight_decay=1e-5, clip_value=1.0)\n",
        "\n",
        "        val_accuracy, val_precision, val_recall, val_cm = evaluate_model_performance(model, val_loader)\n",
        "        print(f'{stage} Model Validation Accuracy: {val_accuracy}')\n",
        "        print(f'{stage} Model Validation Precision: {val_precision}')\n",
        "        print(f'{stage} Model Validation Recall: {val_recall}')\n",
        "        print(f'{stage} Model Validation Confusion Matrix:\\n{val_cm}')\n",
        "\n",
        "        test_accuracy, test_precision, test_recall, test_cm = evaluate_model_performance(model, test_loader)\n",
        "        print(f'{stage} Model Test Accuracy: {test_accuracy}')\n",
        "        print(f'{stage} Model Test Precision: {test_precision}')\n",
        "        print(f'{stage} Model Test Recall: {test_recall}')\n",
        "        print(f'{stage} Model Test Confusion Matrix:\\n{test_cm}')\n"
      ],
      "metadata": {
        "id": "TVww7nwokXsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.Model Implementation**"
      ],
      "metadata": {
        "id": "zVc-GwMpYuKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM with GloVe and Grid_Search for optimal parameter set**"
      ],
      "metadata": {
        "id": "4iNVBMLwk_sj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, aspect_dim, use_attention=False,return_attention = False, dropout=0.5, embedding_matrix=None):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.use_attention = use_attention\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.return_attention = return_attention\n",
        "        if embedding_matrix is not None:\n",
        "            self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "            self.embedding.weight.requires_grad = False\n",
        "        self.aspect_embedding = nn.Embedding(len(aspect_to_idx), aspect_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim + aspect_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        if use_attention:\n",
        "            self.attention = nn.Linear(hidden_dim * 2 + aspect_dim, 1)\n",
        "\n",
        "    def forward(self, reviews, aspects):\n",
        "        embedded_reviews = self.embedding(reviews)\n",
        "        embedded_aspects = self.aspect_embedding(aspects).unsqueeze(1).repeat(1, embedded_reviews.size(1), 1)\n",
        "        lstm_input = torch.cat((embedded_reviews, embedded_aspects), dim=2)\n",
        "        lstm_output, _ = self.lstm(lstm_input)\n",
        "        if self.use_attention:\n",
        "            attn_input = torch.cat((lstm_output, embedded_aspects), dim=2)\n",
        "            attn_weights = F.softmax(self.attention(attn_input), dim=1)\n",
        "            attn_applied = torch.bmm(attn_weights.transpose(1, 2), lstm_output)\n",
        "            final_feature_map = self.dropout(attn_applied.squeeze(1))\n",
        "        else:\n",
        "            final_feature_map = self.dropout(lstm_output[:, -1, :])\n",
        "\n",
        "        output = self.fc(final_feature_map)\n",
        "\n",
        "        if self.use_attention and self.return_attention:\n",
        "            return output, attn_weights\n",
        "        return output"
      ],
      "metadata": {
        "id": "rbpfIYaecf05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modify the train_model function to accept parameters\n",
        "def train_model(model, train_loader, val_loader, epochs, learning_rate, patience, weight_decay, clip_value):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for reviews, aspects, sentiments in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(reviews, aspects)\n",
        "            loss = criterion(outputs, sentiments)\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        val_loss = evaluate_model(model, val_loader)\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss"
      ],
      "metadata": {
        "id": "68o5yz6bcku5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using sklearn's GridSearchCV to automate the hyperparameter tuning\n",
        "def perform_grid_search(train_loader, val_loader, vocab_size, aspect_dim, embedding_matrix):\n",
        "    param_grid = {\n",
        "        'hidden_dim': [64, 128],\n",
        "        'dropout': [0.5, 0.7],\n",
        "        'learning_rate': [0.001, 0.01],\n",
        "        'weight_decay': [1e-4, 1e-5]\n",
        "    }\n",
        "    best_score = 0\n",
        "    best_params = None\n",
        "\n",
        "    for params in ParameterGrid(param_grid):\n",
        "        model = LSTMModel(vocab_size, 300, params['hidden_dim'], 3, aspect_dim, use_attention=True, dropout=params['dropout'], embedding_matrix=embedding_matrix)\n",
        "        train_model(model, train_loader, val_loader, 10, params['learning_rate'], 3, params['weight_decay'], 1.0)\n",
        "        val_accuracy, _, _, _ = evaluate_model_performance(model, val_loader)\n",
        "        if val_accuracy > best_score:\n",
        "            best_score = val_accuracy\n",
        "            best_params = params\n",
        "\n",
        "    return best_params, best_score\n",
        "\n"
      ],
      "metadata": {
        "id": "ujG3CCqzdJae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load glove.6B.300d.txt"
      ],
      "metadata": {
        "id": "T7hUNS1LlOV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlnSdmsgfx80",
        "outputId": "bc98dc85-e454-4d11-8fbf-75d90f36dcd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvcoHZbnf1ob",
        "outputId": "24a231ae-7680-4247-c74f-5ba1e5086112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkGvUnjgf4rK",
        "outputId": "e70f712e-ca76-421d-a005-7b77f85425e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/glove.6B.300d.zip\" -d \"/content\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HksH52If7LM",
        "outputId": "1f143f97-d6cd-4ddc-ce5c-a381ea6abbe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/glove.6B.300d.zip\n",
            "  inflating: /content/glove.6B.300d.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Load and preprocess data\n",
        "    train_data = load_data('train.json')\n",
        "    val_data = load_data('val.json')\n",
        "    test_data = load_data('test.json')\n",
        "\n",
        "    vocab, word_to_idx, aspect_to_idx, sentiment_to_idx = build_vocab_and_mappings(pd.concat([train_data, val_data, test_data]))\n",
        "\n",
        "    train_reviews, train_aspects, train_sentiments = preprocess_data(train_data, word_to_idx, aspect_to_idx, sentiment_to_idx)\n",
        "    val_reviews, val_aspects, val_sentiments = preprocess_data(val_data, word_to_idx, aspect_to_idx, sentiment_to_idx)\n",
        "    test_reviews, test_aspects, test_sentiments = preprocess_data(test_data, word_to_idx, aspect_to_idx, sentiment_to_idx)\n",
        "\n",
        "    # Load GloVe embeddings if desired\n",
        "    embedding_matrix = load_glove_embeddings('glove.6B.300d.txt', word_to_idx)\n",
        "\n",
        "    # Initialize datasets and data loaders\n",
        "    train_dataset = ABSA_Dataset(train_reviews, train_aspects, train_sentiments)\n",
        "    val_dataset = ABSA_Dataset(val_reviews, val_aspects, val_sentiments)\n",
        "    test_dataset = ABSA_Dataset(test_reviews, test_aspects, test_sentiments)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    # Perform grid search\n",
        "    best_params, best_score = perform_grid_search(train_loader, val_loader, len(vocab), len(aspect_to_idx), embedding_matrix)\n",
        "    print(f\"Best Parameters: {best_params}\")\n",
        "    print(f\"Best Validation Score: {best_score}\")\n",
        "\n",
        "    # Train final model with best parameters\n",
        "    final_model_GloVe = LSTMModel(\n",
        "        len(vocab),\n",
        "        300,  # Assuming embedding_dim is 300\n",
        "        best_params['hidden_dim'],\n",
        "        3,  # Assuming output_dim is 3 (e.g., positive, negative, neutral)\n",
        "        len(aspect_to_idx),\n",
        "        use_attention=True,  # Assuming we always use attention\n",
        "        dropout=best_params['dropout'],\n",
        "        embedding_matrix=embedding_matrix\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    train_model(final_model_GloVe, train_loader, val_loader, epochs=10,\n",
        "                learning_rate=best_params['learning_rate'],\n",
        "                patience=5,  # Adjust according to your setup\n",
        "                weight_decay=best_params['weight_decay'])\n",
        "\n",
        "    # Evaluate and save the model\n",
        "    val_accuracy, val_precision, val_recall, val_cm = evaluate_model_performance(final_model_GloVe, val_loader)\n",
        "    print(f'Validation Accuracy: {val_accuracy}')\n",
        "    print(f'Validation Precision: {val_precision}')\n",
        "    print(f'Validation Recall: {val_recall}')\n",
        "    print(f'Validation Confusion Matrix:\\n{val_cm}')\n",
        "\n",
        "    # Save the trained model\n",
        "    torch.save(final_model_GloVe.state_dict(), 'path_to_final_model_GloVe.pth')\n",
        "    print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Fs1KXqydL_-",
        "outputId": "c8b26fbb-8412-46e2-cf42-9e257a04f7f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.0988551496385455, Validation Loss: 1.0856695132596152\n",
            "Epoch 2, Training Loss: 1.0875755859924867, Validation Loss: 1.0754969588347845\n",
            "Epoch 3, Training Loss: 1.07766602195061, Validation Loss: 1.0667213797569275\n",
            "Epoch 4, Training Loss: 1.0697467160654497, Validation Loss: 1.0590374725205558\n",
            "Epoch 5, Training Loss: 1.0624679308216851, Validation Loss: 1.0519102684089117\n",
            "Epoch 6, Training Loss: 1.0570559039846197, Validation Loss: 1.0453973455088479\n",
            "Epoch 7, Training Loss: 1.049886636905842, Validation Loss: 1.0391520261764526\n",
            "Epoch 8, Training Loss: 1.0454610916408333, Validation Loss: 1.0332612948758262\n",
            "Epoch 9, Training Loss: 1.0397945041055079, Validation Loss: 1.0276082711560386\n",
            "Epoch 10, Training Loss: 1.0333872316656887, Validation Loss: 1.0220979835305894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.0896768467920321, Validation Loss: 1.0799452917916434\n",
            "Epoch 2, Training Loss: 1.0823657947617609, Validation Loss: 1.073601735489709\n",
            "Epoch 3, Training Loss: 1.0777501372603682, Validation Loss: 1.068947617496763\n",
            "Epoch 4, Training Loss: 1.073666311062134, Validation Loss: 1.0652854655470168\n",
            "Epoch 5, Training Loss: 1.0705420541333723, Validation Loss: 1.0620635151863098\n",
            "Epoch 6, Training Loss: 1.0684200122549727, Validation Loss: 1.0590717153889793\n",
            "Epoch 7, Training Loss: 1.0641096661219727, Validation Loss: 1.0562647836548942\n",
            "Epoch 8, Training Loss: 1.0626626406703983, Validation Loss: 1.0535263887473516\n",
            "Epoch 9, Training Loss: 1.0599270288471703, Validation Loss: 1.0508714744022913\n",
            "Epoch 10, Training Loss: 1.0586159538041364, Validation Loss: 1.0481854464326585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.0647073976091437, Validation Loss: 1.032025865146092\n",
            "Epoch 2, Training Loss: 1.0208960280225083, Validation Loss: 0.9954320809670857\n",
            "Epoch 3, Training Loss: 0.9955533869094677, Validation Loss: 0.9708382487297058\n",
            "Epoch 4, Training Loss: 0.9781076698689848, Validation Loss: 0.9538076434816632\n",
            "Epoch 5, Training Loss: 0.9629464944203695, Validation Loss: 0.9403399718659264\n",
            "Epoch 6, Training Loss: 0.955417370205527, Validation Loss: 0.9318751714059285\n",
            "Epoch 7, Training Loss: 0.9496807053282454, Validation Loss: 0.9262628363711494\n",
            "Epoch 8, Training Loss: 0.9441053029653188, Validation Loss: 0.9206281027623585\n",
            "Epoch 9, Training Loss: 0.9380247163343, Validation Loss: 0.9181205758026668\n",
            "Epoch 10, Training Loss: 0.9352446354187287, Validation Loss: 0.9140524502311435\n",
            "Epoch 1, Training Loss: 1.045704449619259, Validation Loss: 0.9968132653406688\n",
            "Epoch 2, Training Loss: 0.9897146751214793, Validation Loss: 0.9557842995439257\n",
            "Epoch 3, Training Loss: 0.9665783031566723, Validation Loss: 0.9359249281031745\n",
            "Epoch 4, Training Loss: 0.9553283917474317, Validation Loss: 0.9238291680812836\n",
            "Epoch 5, Training Loss: 0.9478749404619405, Validation Loss: 0.9164656613554273\n",
            "Epoch 6, Training Loss: 0.9419507419203853, Validation Loss: 0.9116452272449221\n",
            "Epoch 7, Training Loss: 0.9355508518648578, Validation Loss: 0.9083812470946994\n",
            "Epoch 8, Training Loss: 0.9314817053240698, Validation Loss: 0.90570082621915\n",
            "Epoch 9, Training Loss: 0.9300388266911378, Validation Loss: 0.903536108987672\n",
            "Epoch 10, Training Loss: 0.9252563637119156, Validation Loss: 0.9020866240773883\n",
            "Epoch 1, Training Loss: 1.0943721747613169, Validation Loss: 1.0844107568264008\n",
            "Epoch 2, Training Loss: 1.0770058556719944, Validation Loss: 1.0688041704041618\n",
            "Epoch 3, Training Loss: 1.0639771061974603, Validation Loss: 1.0564035475254059\n",
            "Epoch 4, Training Loss: 1.0528439576024409, Validation Loss: 1.0458023846149445\n",
            "Epoch 5, Training Loss: 1.0432526906868358, Validation Loss: 1.036460354924202\n",
            "Epoch 6, Training Loss: 1.03480665211205, Validation Loss: 1.027804704649108\n",
            "Epoch 7, Training Loss: 1.0261870453486572, Validation Loss: 1.0197166970797948\n",
            "Epoch 8, Training Loss: 1.019345767863162, Validation Loss: 1.012123322912625\n",
            "Epoch 9, Training Loss: 1.0136595083786561, Validation Loss: 1.0048427964959825\n",
            "Epoch 10, Training Loss: 1.0063292043166117, Validation Loss: 0.9978637056691306\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.0797797044118245, Validation Loss: 1.073936104774475\n",
            "Epoch 2, Training Loss: 1.0692264757177852, Validation Loss: 1.0630508320672172\n",
            "Epoch 3, Training Loss: 1.0612543802540582, Validation Loss: 1.053733961922782\n",
            "Epoch 4, Training Loss: 1.0538815380753697, Validation Loss: 1.0452435612678528\n",
            "Epoch 5, Training Loss: 1.0455437334808144, Validation Loss: 1.0373016425541468\n",
            "Epoch 6, Training Loss: 1.0397904472308115, Validation Loss: 1.0297047282968248\n",
            "Epoch 7, Training Loss: 1.032935021696864, Validation Loss: 1.0224569950784956\n",
            "Epoch 8, Training Loss: 1.0246797332892548, Validation Loss: 1.0153181850910187\n",
            "Epoch 9, Training Loss: 1.018505035488455, Validation Loss: 1.0084360433476312\n",
            "Epoch 10, Training Loss: 1.0128745707842681, Validation Loss: 1.0016932785511017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.0484592536011257, Validation Loss: 1.0111071999583925\n",
            "Epoch 2, Training Loss: 0.9942904192585129, Validation Loss: 0.9659185622419629\n",
            "Epoch 3, Training Loss: 0.9641426514397871, Validation Loss: 0.9418045324938638\n",
            "Epoch 4, Training Loss: 0.950458637765936, Validation Loss: 0.930301200066294\n",
            "Epoch 5, Training Loss: 0.9432023398511045, Validation Loss: 0.9235838417496\n",
            "Epoch 6, Training Loss: 0.9375115412849564, Validation Loss: 0.9173138844115394\n",
            "Epoch 7, Training Loss: 0.9354893981336473, Validation Loss: 0.9134509457009179\n",
            "Epoch 8, Training Loss: 0.9325645912337948, Validation Loss: 0.9110856865133558\n",
            "Epoch 9, Training Loss: 0.9297208034240447, Validation Loss: 0.9082958059651511\n",
            "Epoch 10, Training Loss: 0.9264369223031912, Validation Loss: 0.9054903898920331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.0551415211982555, Validation Loss: 1.02139578972544\n",
            "Epoch 2, Training Loss: 1.0075302822095853, Validation Loss: 0.9774589261838368\n",
            "Epoch 3, Training Loss: 0.9745207828981383, Validation Loss: 0.9480061594929013\n",
            "Epoch 4, Training Loss: 0.9551059697662387, Validation Loss: 0.9312806065593447\n",
            "Epoch 5, Training Loss: 0.9478453024550602, Validation Loss: 0.9226797286953244\n",
            "Epoch 6, Training Loss: 0.9415699756360268, Validation Loss: 0.9173632924045835\n",
            "Epoch 7, Training Loss: 0.9382051632211015, Validation Loss: 0.9131746483700616\n",
            "Epoch 8, Training Loss: 0.9328537484010061, Validation Loss: 0.9103063515254429\n",
            "Epoch 9, Training Loss: 0.931975669957496, Validation Loss: 0.9076674090964454\n",
            "Epoch 10, Training Loss: 0.9296591826924333, Validation Loss: 0.9055243900844029\n",
            "Epoch 1, Training Loss: 1.1023750417941325, Validation Loss: 1.0927932177271162\n",
            "Epoch 2, Training Loss: 1.09200335515512, Validation Loss: 1.0860148753438676\n",
            "Epoch 3, Training Loss: 1.088055094620129, Validation Loss: 1.0812338420322962\n",
            "Epoch 4, Training Loss: 1.0837627574130222, Validation Loss: 1.0777039996215276\n",
            "Epoch 5, Training Loss: 1.0811435886331506, Validation Loss: 1.074957664523806\n",
            "Epoch 6, Training Loss: 1.078004078016625, Validation Loss: 1.072627957378115\n",
            "Epoch 7, Training Loss: 1.0753696375602, Validation Loss: 1.0706167476517814\n",
            "Epoch 8, Training Loss: 1.0746146813706234, Validation Loss: 1.0688377235616957\n",
            "Epoch 9, Training Loss: 1.071241398920884, Validation Loss: 1.06714471748897\n",
            "Epoch 10, Training Loss: 1.0717400986332077, Validation Loss: 1.0654730669089727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.1163841743726988, Validation Loss: 1.1030048089368003\n",
            "Epoch 2, Training Loss: 1.0983900701677478, Validation Loss: 1.088604177747454\n",
            "Epoch 3, Training Loss: 1.0885321062964362, Validation Loss: 1.0773470912660872\n",
            "Epoch 4, Training Loss: 1.0785074481019028, Validation Loss: 1.0682763797896249\n",
            "Epoch 5, Training Loss: 1.0698585566636678, Validation Loss: 1.0602959096431732\n",
            "Epoch 6, Training Loss: 1.0650041398701366, Validation Loss: 1.0533740988799505\n",
            "Epoch 7, Training Loss: 1.0567462812135886, Validation Loss: 1.047065304858344\n",
            "Epoch 8, Training Loss: 1.052214802116961, Validation Loss: 1.0411902942827769\n",
            "Epoch 9, Training Loss: 1.0465459914894792, Validation Loss: 1.0355515352317266\n",
            "Epoch 10, Training Loss: 1.0451251587889216, Validation Loss: 1.0303494312933512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.037540697031193, Validation Loss: 0.9843074487788337\n",
            "Epoch 2, Training Loss: 0.9830419158076381, Validation Loss: 0.939133597271783\n",
            "Epoch 3, Training Loss: 0.954351055997986, Validation Loss: 0.919145154101508\n",
            "Epoch 4, Training Loss: 0.9471228192518423, Validation Loss: 0.9112492480448314\n",
            "Epoch 5, Training Loss: 0.9407390348009161, Validation Loss: 0.9070268848112651\n",
            "Epoch 6, Training Loss: 0.9375436120742077, Validation Loss: 0.9046697531427655\n",
            "Epoch 7, Training Loss: 0.9298277835588198, Validation Loss: 0.9028164318629673\n",
            "Epoch 8, Training Loss: 0.934819180954684, Validation Loss: 0.9018261496509824\n",
            "Epoch 9, Training Loss: 0.9301171547120756, Validation Loss: 0.9009361820561546\n",
            "Epoch 10, Training Loss: 0.9301081493094161, Validation Loss: 0.9005579948425293\n",
            "Epoch 1, Training Loss: 1.0575917478617247, Validation Loss: 1.0258926153182983\n",
            "Epoch 2, Training Loss: 1.019926073851886, Validation Loss: 0.9904054914202008\n",
            "Epoch 3, Training Loss: 0.9948280593296429, Validation Loss: 0.9675493495804923\n",
            "Epoch 4, Training Loss: 0.9766008716982764, Validation Loss: 0.9518549612590245\n",
            "Epoch 5, Training Loss: 0.9635795376322291, Validation Loss: 0.9391124716826847\n",
            "Epoch 6, Training Loss: 0.9556621452709576, Validation Loss: 0.9318448241267886\n",
            "Epoch 7, Training Loss: 0.9467065997488864, Validation Loss: 0.9264103536094938\n",
            "Epoch 8, Training Loss: 0.9471158167800388, Validation Loss: 0.9221564914499011\n",
            "Epoch 9, Training Loss: 0.9400463794265781, Validation Loss: 0.9197045628513608\n",
            "Epoch 10, Training Loss: 0.9371142929738706, Validation Loss: 0.9193481313330787\n",
            "Epoch 1, Training Loss: 1.088803113580824, Validation Loss: 1.0812816705022539\n",
            "Epoch 2, Training Loss: 1.0801231973880046, Validation Loss: 1.0728308388165064\n",
            "Epoch 3, Training Loss: 1.0724083399987436, Validation Loss: 1.066984508718763\n",
            "Epoch 4, Training Loss: 1.0675405126971167, Validation Loss: 1.0623158429350172\n",
            "Epoch 5, Training Loss: 1.0638770095936887, Validation Loss: 1.058301912886756\n",
            "Epoch 6, Training Loss: 1.060632062387896, Validation Loss: 1.054536189351763\n",
            "Epoch 7, Training Loss: 1.0574694662480741, Validation Loss: 1.050788904939379\n",
            "Epoch 8, Training Loss: 1.0552036217204086, Validation Loss: 1.047193901879447\n",
            "Epoch 9, Training Loss: 1.0523202838124455, Validation Loss: 1.0436465059007918\n",
            "Epoch 10, Training Loss: 1.048221319108396, Validation Loss: 1.0401403776236944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.0836546539186358, Validation Loss: 1.0696849056652613\n",
            "Epoch 2, Training Loss: 1.07226336378235, Validation Loss: 1.0592577840600694\n",
            "Epoch 3, Training Loss: 1.0615722477973044, Validation Loss: 1.0515927970409393\n",
            "Epoch 4, Training Loss: 1.0601238272748552, Validation Loss: 1.0453332151685442\n",
            "Epoch 5, Training Loss: 1.0521778837517575, Validation Loss: 1.0394458643027715\n",
            "Epoch 6, Training Loss: 1.0476131968133084, Validation Loss: 1.0340891927480698\n",
            "Epoch 7, Training Loss: 1.045302178140159, Validation Loss: 1.029166694198336\n",
            "Epoch 8, Training Loss: 1.038841247021615, Validation Loss: 1.0244179133858\n",
            "Epoch 9, Training Loss: 1.0318560858030577, Validation Loss: 1.0197714567184448\n",
            "Epoch 10, Training Loss: 1.030000951913026, Validation Loss: 1.0153345039912633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.0525081563103307, Validation Loss: 1.0105844203914915\n",
            "Epoch 2, Training Loss: 1.00531487636738, Validation Loss: 0.9784868082829884\n",
            "Epoch 3, Training Loss: 0.9853973125552272, Validation Loss: 0.963143412555967\n",
            "Epoch 4, Training Loss: 0.9758130706645347, Validation Loss: 0.954184176666396\n",
            "Epoch 5, Training Loss: 0.9707176113450849, Validation Loss: 0.9493736071246011\n",
            "Epoch 6, Training Loss: 0.9673347583225181, Validation Loss: 0.9438191183975765\n",
            "Epoch 7, Training Loss: 0.9603371614808435, Validation Loss: 0.9390991032123566\n",
            "Epoch 8, Training Loss: 0.9590330899835707, Validation Loss: 0.9355548598936626\n",
            "Epoch 9, Training Loss: 0.9541618904551944, Validation Loss: 0.9308208440031324\n",
            "Epoch 10, Training Loss: 0.9508759948584411, Validation Loss: 0.9264481323105949\n",
            "Epoch 1, Training Loss: 1.0650535467508677, Validation Loss: 1.0312049452747618\n",
            "Epoch 2, Training Loss: 1.0204413468773301, Validation Loss: 0.9904837267739433\n",
            "Epoch 3, Training Loss: 0.9935312649688205, Validation Loss: 0.9627711474895477\n",
            "Epoch 4, Training Loss: 0.9738778141704766, Validation Loss: 0.9453449100255966\n",
            "Epoch 5, Training Loss: 0.9637069178594125, Validation Loss: 0.9341347238847187\n",
            "Epoch 6, Training Loss: 0.956088713697485, Validation Loss: 0.925315478018352\n",
            "Epoch 7, Training Loss: 0.9489339002080865, Validation Loss: 0.920231853212629\n",
            "Epoch 8, Training Loss: 0.9461590881283218, Validation Loss: 0.9150282314845494\n",
            "Epoch 9, Training Loss: 0.9416322917551607, Validation Loss: 0.9109740683010646\n",
            "Epoch 10, Training Loss: 0.9366276368901536, Validation Loss: 0.907108696443694\n",
            "Best Parameters: {'dropout': 0.5, 'hidden_dim': 64, 'learning_rate': 0.01, 'weight_decay': 1e-05}\n",
            "Best Validation Score: 0.6002252252252253\n",
            "Epoch 1, Training Loss: 1.0556403019943752, Validation Loss: 1.01899134687015\n",
            "Epoch 2, Training Loss: 1.0041662860024083, Validation Loss: 0.9760731671537671\n",
            "Epoch 3, Training Loss: 0.972371481560372, Validation Loss: 0.9489117796931948\n",
            "Epoch 4, Training Loss: 0.9566620846052427, Validation Loss: 0.9337225151913506\n",
            "Epoch 5, Training Loss: 0.9455357059702143, Validation Loss: 0.923670061997005\n",
            "Epoch 6, Training Loss: 0.9370170922966691, Validation Loss: 0.9161456163440432\n",
            "Epoch 7, Training Loss: 0.9323936735724544, Validation Loss: 0.911160192319325\n",
            "Epoch 8, Training Loss: 0.9315499684832118, Validation Loss: 0.9079152303082603\n",
            "Epoch 9, Training Loss: 0.9304552513199884, Validation Loss: 0.9052983543702534\n",
            "Epoch 10, Training Loss: 0.9244148712437432, Validation Loss: 0.902910651905196\n",
            "Validation Accuracy: 0.5912162162162162\n",
            "Validation Precision: 0.5778217681418721\n",
            "Validation Recall: 0.5912162162162162\n",
            "Validation Confusion Matrix:\n",
            "[[ 14  59 168]\n",
            " [ 10 158  91]\n",
            " [  3  32 353]]\n",
            "Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LSTM with Word2Vec and Grid_Search for Hyperparameter**"
      ],
      "metadata": {
        "id": "jzEB_4_TlXHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter search\n",
        "def grid_search(train_loader, val_loader, param_grid):\n",
        "    param_grid = list(ParameterGrid(param_grid))\n",
        "    best_params = None\n",
        "    best_val_accuracy = 0\n",
        "\n",
        "    for params in param_grid:\n",
        "        print(f\"Training with params: {params}\")\n",
        "        model = LSTMModel(len(vocab), params['embedding_dim'], params['hidden_dim'], 3, len(aspect_to_idx),\n",
        "                          use_attention=params['use_attention'], dropout=params['dropout'], embedding_matrix=embedding_matrix)\n",
        "        train_model(model, train_loader, val_loader, epochs=params['epochs'], learning_rate=params['learning_rate'],\n",
        "                    patience=params['patience'], weight_decay=params['weight_decay'], clip_value=params['clip_value'])\n",
        "\n",
        "        val_accuracy, val_precision, val_recall, val_cm = evaluate_model_performance(model, val_loader)\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            best_params = params\n",
        "        print(f\"Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "    print(f\"Best params: {best_params}, Best Validation Accuracy: {best_val_accuracy}\")\n",
        "    return best_params"
      ],
      "metadata": {
        "id": "DNONCkBQB-s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, aspect_dim, use_attention=False, return_attention=False, dropout=0.5, embedding_matrix=None):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.use_attention = use_attention\n",
        "        self.return_attention = return_attention  # control the return of attention value\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        if embedding_matrix is not None:\n",
        "            self.embedding.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "            self.embedding.weight.requires_grad = False  # Optionally freeze embeddings\n",
        "        self.aspect_embedding = nn.Embedding(len(aspect_to_idx), aspect_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim + aspect_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        if use_attention:\n",
        "            self.attention = nn.Linear(hidden_dim * 2 + aspect_dim, 1)\n",
        "\n",
        "    def forward(self, reviews, aspects):\n",
        "        embedded_reviews = self.embedding(reviews)\n",
        "        embedded_aspects = self.aspect_embedding(aspects).unsqueeze(1).repeat(1, embedded_reviews.size(1), 1)\n",
        "        lstm_input = torch.cat((embedded_reviews, embedded_aspects), dim=2)\n",
        "        lstm_output, _ = self.lstm(lstm_input)\n",
        "\n",
        "        if self.use_attention:\n",
        "            attn_input = torch.cat((lstm_output, embedded_aspects), dim=2)\n",
        "            attn_scores = self.attention(attn_input)\n",
        "            attn_weights = F.softmax(attn_scores, dim=1)\n",
        "            attn_applied = torch.bmm(attn_weights.transpose(1, 2), lstm_output)\n",
        "            final_feature_map = self.dropout(attn_applied.squeeze(1))\n",
        "        else:\n",
        "            final_feature_map = self.dropout(lstm_output[:, -1, :])\n",
        "\n",
        "        output = self.fc(final_feature_map)\n",
        "\n",
        "        if self.use_attention and self.return_attention:\n",
        "            return output, attn_weights\n",
        "        return output\n",
        "\n"
      ],
      "metadata": {
        "id": "IBA5FxK_CJdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function with early stopping, learning rate scheduler, and gradient clipping\n",
        "def train_model(model, train_loader, val_loader, epochs, learning_rate, patience=3, weight_decay=0.0, clip_value=1.0):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for reviews, aspects, sentiments in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(reviews, aspects)\n",
        "            loss = criterion(outputs, sentiments)\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        val_loss = evaluate_model(model, val_loader)\n",
        "        scheduler.step(val_loss)\n",
        "        print(f'Epoch {epoch+1}, Training Loss: {total_loss/len(train_loader)}, Validation Loss: {val_loss/len(val_loader)}')\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break"
      ],
      "metadata": {
        "id": "10lm5GLMCM5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    with torch.no_grad():\n",
        "        for reviews, aspects, sentiments in val_loader:\n",
        "            outputs = model(reviews, aspects)\n",
        "            loss = criterion(outputs, sentiments)\n",
        "            total_loss += loss.item()\n",
        "    return total_loss\n",
        "\n",
        "# Evaluate model performance\n",
        "def evaluate_model_performance(model, data_loader):\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for reviews, aspects, sentiments in data_loader:\n",
        "            outputs = model(reviews, aspects)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(sentiments.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    precision = precision_score(all_labels, all_predictions, average='weighted')\n",
        "    recall = recall_score(all_labels, all_predictions, average='weighted')\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "    return accuracy, precision, recall, cm"
      ],
      "metadata": {
        "id": "90lIUoGwCORT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    # Load and preprocess data\n",
        "    train_data = load_data('train.json')\n",
        "    val_data = load_data('val.json')\n",
        "    test_data = load_data('test.json')\n",
        "\n",
        "    vocab, word_to_idx, aspect_to_idx, sentiment_to_idx = build_vocab_and_mappings(pd.concat([train_data, val_data, test_data]))\n",
        "\n",
        "    train_reviews, train_aspects, train_sentiments = preprocess_data(train_data, word_to_idx, aspect_to_idx, sentiment_to_idx)\n",
        "    val_reviews, val_aspects, val_sentiments = preprocess_data(val_data, word_to_idx, aspect_to_idx, sentiment_to_idx)\n",
        "    test_reviews, test_aspects, test_sentiments = preprocess_data(test_data, word_to_idx, aspect_to_idx, sentiment_to_idx)\n",
        "\n",
        "    # Load Word2Vec embeddings\n",
        "    word2vec_model = api.load('word2vec-google-news-300')\n",
        "    embedding_matrix = load_word2vec_embeddings(word2vec_model, word_to_idx)\n",
        "\n",
        "    # Initialize datasets and data loaders\n",
        "    train_dataset = ABSA_Dataset(train_reviews, train_aspects, train_sentiments)\n",
        "    val_dataset = ABSA_Dataset(val_reviews, val_aspects, val_sentiments)\n",
        "    test_dataset = ABSA_Dataset(test_reviews, test_aspects, test_sentiments)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    # Hyperparameter grid search\n",
        "    param_grid = {\n",
        "        'embedding_dim': [300],\n",
        "        'hidden_dim': [64],\n",
        "        'use_attention': [True],\n",
        "        'dropout': [0.5],\n",
        "        'epochs': [10,20],\n",
        "        'learning_rate': [0.001, 0.01],\n",
        "        'patience': [3,5],\n",
        "        'weight_decay': [1e-4, 1e-5],\n",
        "        'clip_value': [1.0]\n",
        "    }\n",
        "    best_params = grid_search(train_loader, val_loader, param_grid)\n",
        "\n",
        "    # Train final model with best parameters\n",
        "    final_model = LSTMModel(len(vocab), best_params['embedding_dim'], best_params['hidden_dim'], 3, len(aspect_to_idx),\n",
        "                            use_attention=best_params['use_attention'], dropout=best_params['dropout'], embedding_matrix=embedding_matrix)\n",
        "    train_model(final_model, train_loader, val_loader, epochs=best_params['epochs'], learning_rate=best_params['learning_rate'],\n",
        "                patience=best_params['patience'], weight_decay=best_params['weight_decay'], clip_value=best_params['clip_value'])\n",
        "\n",
        "    # Evaluate final model performance\n",
        "    val_accuracy, val_precision, val_recall, val_cm = evaluate_model_performance(final_model, val_loader)\n",
        "    print(f'Final Validation Accuracy: {val_accuracy}')\n",
        "    print(f'Final Validation Precision: {val_precision}')\n",
        "    print(f'Final Validation Recall: {val_recall}')\n",
        "    print(f'Final Validation Confusion Matrix:\\n{val_cm}')\n",
        "\n",
        "    test_accuracy, test_precision, test_recall, test_cm = evaluate_model_performance(final_model, test_loader)\n",
        "    print(f'Final Test Accuracy: {test_accuracy}')\n",
        "    print(f'Final Test Precision: {test_precision}')\n",
        "    print(f'Final Test Recall: {test_recall}')\n",
        "    print(f'Final Test Confusion Matrix:\\n{test_cm}')"
      ],
      "metadata": {
        "id": "JJ-m2kQv9-f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66826515-d68c-4c0e-bdf3-96f6cba3299b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training with params: {'clip_value': 1.0, 'dropout': 0.5, 'embedding_dim': 300, 'epochs': 10, 'hidden_dim': 64, 'learning_rate': 0.001, 'patience': 3, 'use_attention': True, 'weight_decay': 0.0001}\n",
            "Epoch 1, Training Loss: 1.1095963082871996, Validation Loss: 1.0961687053952898\n",
            "Epoch 2, Training Loss: 1.0866952758651596, Validation Loss: 1.073012215750558\n",
            "Epoch 3, Training Loss: 1.0688678896104968, Validation Loss: 1.0549434678895133\n",
            "Epoch 4, Training Loss: 1.0553732557339712, Validation Loss: 1.0405311371598924\n",
            "Epoch 5, Training Loss: 1.0442651819001447, Validation Loss: 1.0287043069090163\n",
            "Epoch 6, Training Loss: 1.035262378486427, Validation Loss: 1.018949908869607\n",
            "Epoch 7, Training Loss: 1.030064933740341, Validation Loss: 1.010693290403911\n",
            "Epoch 8, Training Loss: 1.0230323511200983, Validation Loss: 1.003521284886769\n",
            "Epoch 9, Training Loss: 1.0183171240596083, Validation Loss: 0.9973858169146946\n",
            "Epoch 10, Training Loss: 1.0128358860273619, Validation Loss: 0.9919011784451348\n",
            "Validation Accuracy: 0.5608108108108109\n",
            "Training with params: {'clip_value': 1.0, 'dropout': 0.5, 'embedding_dim': 300, 'epochs': 10, 'hidden_dim': 64, 'learning_rate': 0.001, 'patience': 3, 'use_attention': True, 'weight_decay': 1e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.1005733115179044, Validation Loss: 1.094179323741368\n",
            "Epoch 2, Training Loss: 1.08934532629477, Validation Loss: 1.0825557197843279\n",
            "Epoch 3, Training Loss: 1.0781954575229336, Validation Loss: 1.0721919238567352\n",
            "Epoch 4, Training Loss: 1.0693752040734161, Validation Loss: 1.0627621582576208\n",
            "Epoch 5, Training Loss: 1.060126171455727, Validation Loss: 1.054270327091217\n",
            "Epoch 6, Training Loss: 1.0517455156858977, Validation Loss: 1.0464836699622018\n",
            "Epoch 7, Training Loss: 1.0451275706291199, Validation Loss: 1.0393622176987785\n",
            "Epoch 8, Training Loss: 1.038597464292973, Validation Loss: 1.0326496213674545\n",
            "Epoch 9, Training Loss: 1.031849750258901, Validation Loss: 1.0264195586953844\n",
            "Epoch 10, Training Loss: 1.026629797778688, Validation Loss: 1.0206963952098573\n",
            "Validation Accuracy: 0.5574324324324325\n",
            "Training with params: {'clip_value': 1.0, 'dropout': 0.5, 'embedding_dim': 300, 'epochs': 10, 'hidden_dim': 64, 'learning_rate': 0.001, 'patience': 5, 'use_attention': True, 'weight_decay': 0.0001}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.0917765256520864, Validation Loss: 1.0854348497731345\n",
            "Epoch 2, Training Loss: 1.0819518141918354, Validation Loss: 1.0752782608781541\n",
            "Epoch 3, Training Loss: 1.0735213037009712, Validation Loss: 1.066443805183683\n",
            "Epoch 4, Training Loss: 1.06587612091958, Validation Loss: 1.0586635512965066\n",
            "Epoch 5, Training Loss: 1.0590232143530975, Validation Loss: 1.0517368699823106\n",
            "Epoch 6, Training Loss: 1.053687713973157, Validation Loss: 1.045489149434226\n",
            "Epoch 7, Training Loss: 1.048488445647128, Validation Loss: 1.0398130927767073\n",
            "Epoch 8, Training Loss: 1.042325487007966, Validation Loss: 1.0346107546772276\n",
            "Epoch 9, Training Loss: 1.0376681728405996, Validation Loss: 1.0297688565083913\n",
            "Epoch 10, Training Loss: 1.0338830351829529, Validation Loss: 1.0252892289842879\n",
            "Validation Accuracy: 0.5574324324324325\n",
            "Training with params: {'clip_value': 1.0, 'dropout': 0.5, 'embedding_dim': 300, 'epochs': 10, 'hidden_dim': 64, 'learning_rate': 0.001, 'patience': 5, 'use_attention': True, 'weight_decay': 1e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.1003850091685046, Validation Loss: 1.092415064573288\n",
            "Epoch 2, Training Loss: 1.0875405518858283, Validation Loss: 1.0798982211521693\n",
            "Epoch 3, Training Loss: 1.0765895440771773, Validation Loss: 1.0691064085279192\n",
            "Epoch 4, Training Loss: 1.0661687665694468, Validation Loss: 1.0596302364553725\n",
            "Epoch 5, Training Loss: 1.0577866354504146, Validation Loss: 1.0512336535113198\n",
            "Epoch 6, Training Loss: 1.049751084398579, Validation Loss: 1.0436590484210424\n",
            "Epoch 7, Training Loss: 1.043484892662581, Validation Loss: 1.0367235562631063\n",
            "Epoch 8, Training Loss: 1.0382711484625533, Validation Loss: 1.0302864100251878\n",
            "Epoch 9, Training Loss: 1.0328547393416498, Validation Loss: 1.024380624294281\n",
            "Epoch 10, Training Loss: 1.0261390751546569, Validation Loss: 1.0187536073582513\n",
            "Validation Accuracy: 0.5574324324324325\n",
            "Training with params: {'clip_value': 1.0, 'dropout': 0.5, 'embedding_dim': 300, 'epochs': 10, 'hidden_dim': 64, 'learning_rate': 0.01, 'patience': 3, 'use_attention': True, 'weight_decay': 0.0001}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.0487424634598397, Validation Loss: 1.0101623428719384\n",
            "Epoch 2, Training Loss: 0.9951091435578492, Validation Loss: 0.9655696941273553\n",
            "Epoch 3, Training Loss: 0.9643510185383461, Validation Loss: 0.9412297031709126\n",
            "Epoch 4, Training Loss: 0.9507141744231319, Validation Loss: 0.9295915194920131\n",
            "Epoch 5, Training Loss: 0.9415134803668873, Validation Loss: 0.9238048046827316\n",
            "Epoch 6, Training Loss: 0.9386082125139666, Validation Loss: 0.9199306475264686\n",
            "Epoch 7, Training Loss: 0.9360192949707443, Validation Loss: 0.9174722816262927\n",
            "Epoch 8, Training Loss: 0.9331880354129516, Validation Loss: 0.9153101891279221\n",
            "Epoch 9, Training Loss: 0.9331162926313039, Validation Loss: 0.9139376005956105\n",
            "Epoch 10, Training Loss: 0.9305392066100696, Validation Loss: 0.9126777670213154\n",
            "Validation Accuracy: 0.5990990990990991\n",
            "Training with params: {'clip_value': 1.0, 'dropout': 0.5, 'embedding_dim': 300, 'epochs': 10, 'hidden_dim': 64, 'learning_rate': 0.01, 'patience': 3, 'use_attention': True, 'weight_decay': 1e-05}\n",
            "Epoch 1, Training Loss: 1.0753258316366523, Validation Loss: 1.0513049491814204\n",
            "Epoch 2, Training Loss: 1.0386245030540604, Validation Loss: 1.0245451820748193\n",
            "Epoch 3, Training Loss: 1.0157686509527601, Validation Loss: 1.0032248347997665\n",
            "Epoch 4, Training Loss: 0.9974108735720316, Validation Loss: 0.9847938418388367\n",
            "Epoch 5, Training Loss: 0.9842853146093385, Validation Loss: 0.96885875080313\n",
            "Epoch 6, Training Loss: 0.9720706093955684, Validation Loss: 0.9549196788242885\n",
            "Epoch 7, Training Loss: 0.961512099246721, Validation Loss: 0.9439016239983695\n",
            "Epoch 8, Training Loss: 0.9559593077178474, Validation Loss: 0.9351305365562439\n",
            "Epoch 9, Training Loss: 0.9510315490198565, Validation Loss: 0.9284066643033709\n",
            "Epoch 10, Training Loss: 0.9468540299583126, Validation Loss: 0.9228900053671428\n",
            "Validation Accuracy: 0.5900900900900901\n",
            "Training with params: {'clip_value': 1.0, 'dropout': 0.5, 'embedding_dim': 300, 'epochs': 10, 'hidden_dim': 64, 'learning_rate': 0.01, 'patience': 5, 'use_attention': True, 'weight_decay': 0.0001}\n",
            "Epoch 1, Training Loss: 1.0720257254334185, Validation Loss: 1.0497368957315172\n",
            "Epoch 2, Training Loss: 1.036426917658196, Validation Loss: 1.0198895462921687\n",
            "Epoch 3, Training Loss: 1.0047850871945287, Validation Loss: 0.9905913855348315\n",
            "Epoch 4, Training Loss: 0.9762305023970904, Validation Loss: 0.9642052203416824\n",
            "Epoch 5, Training Loss: 0.9573391649100158, Validation Loss: 0.9456294178962708\n",
            "Epoch 6, Training Loss: 0.9443070260254113, Validation Loss: 0.9338096976280212\n",
            "Epoch 7, Training Loss: 0.9365499196825801, Validation Loss: 0.9267077360834394\n",
            "Epoch 8, Training Loss: 0.9332511285403827, Validation Loss: 0.9225943216255733\n",
            "Epoch 9, Training Loss: 0.9327012560926042, Validation Loss: 0.9186491348913738\n",
            "Epoch 10, Training Loss: 0.9330712315198537, Validation Loss: 0.9153258545058114\n",
            "Validation Accuracy: 0.5990990990990991\n",
            "Training with params: {'clip_value': 1.0, 'dropout': 0.5, 'embedding_dim': 300, 'epochs': 10, 'hidden_dim': 64, 'learning_rate': 0.01, 'patience': 5, 'use_attention': True, 'weight_decay': 1e-05}\n",
            "Epoch 1, Training Loss: 1.0644816579045475, Validation Loss: 1.0341390541621618\n",
            "Epoch 2, Training Loss: 1.0266018246745203, Validation Loss: 0.9986930936574936\n",
            "Epoch 3, Training Loss: 0.9990111624335384, Validation Loss: 0.9699190706014633\n",
            "Epoch 4, Training Loss: 0.9804472112440848, Validation Loss: 0.9489750734397343\n",
            "Epoch 5, Training Loss: 0.9647965117080791, Validation Loss: 0.9366340530770165\n",
            "Epoch 6, Training Loss: 0.9573503238660795, Validation Loss: 0.927904663341386\n",
            "Epoch 7, Training Loss: 0.9505493922813518, Validation Loss: 0.9227879792451859\n",
            "Epoch 8, Training Loss: 0.9452806687032854, Validation Loss: 0.9189851709774562\n",
            "Epoch 9, Training Loss: 0.9429235536235947, Validation Loss: 0.9168762075049537\n",
            "Epoch 10, Training Loss: 0.9367217271177618, Validation Loss: 0.9142350235155651\n",
            "Validation Accuracy: 0.5822072072072072\n",
            "Training with params: {'clip_value': 1.0, 'dropout': 0.5, 'embedding_dim': 300, 'epochs': 20, 'hidden_dim': 64, 'learning_rate': 0.001, 'patience': 3, 'use_attention': True, 'weight_decay': 0.0001}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.1024147524490013, Validation Loss: 1.0926674008369446\n",
            "Epoch 2, Training Loss: 1.0869055014472824, Validation Loss: 1.0769441851547785\n",
            "Epoch 3, Training Loss: 1.0729351849169344, Validation Loss: 1.0628915088517326\n",
            "Epoch 4, Training Loss: 1.061286660196545, Validation Loss: 1.050231661115374\n",
            "Epoch 5, Training Loss: 1.049321108036213, Validation Loss: 1.0385374618428094\n",
            "Epoch 6, Training Loss: 1.0389511695316247, Validation Loss: 1.0278428473642893\n",
            "Epoch 7, Training Loss: 1.0303371427832424, Validation Loss: 1.017989190561431\n",
            "Epoch 8, Training Loss: 1.0228600343605418, Validation Loss: 1.0088529757090978\n",
            "Epoch 9, Training Loss: 1.0151566820101694, Validation Loss: 1.0004090751920427\n",
            "Epoch 10, Training Loss: 1.008646267491418, Validation Loss: 0.9926493508475167\n",
            "Epoch 11, Training Loss: 1.0024445588524278, Validation Loss: 0.9855168823684964\n",
            "Epoch 12, Training Loss: 0.996385565212181, Validation Loss: 0.9789022909743446\n",
            "Epoch 13, Training Loss: 0.9924440625551585, Validation Loss: 0.972906734262194\n",
            "Epoch 14, Training Loss: 0.9875764862911122, Validation Loss: 0.9674252697399685\n",
            "Epoch 15, Training Loss: 0.9816832606856888, Validation Loss: 0.9623795534883227\n",
            "Epoch 16, Training Loss: 0.9800712160162024, Validation Loss: 0.9578282960823604\n",
            "Epoch 17, Training Loss: 0.9762045942448281, Validation Loss: 0.9537269238914762\n",
            "Epoch 18, Training Loss: 0.9732606561334284, Validation Loss: 0.9499874923910413\n",
            "Epoch 19, Training Loss: 0.971301046040681, Validation Loss: 0.9466514076505389\n",
            "Epoch 20, Training Loss: 0.9671706232401702, Validation Loss: 0.9435499438217708\n",
            "Validation Accuracy: 0.5630630630630631\n",
            "Training with params: {'clip_value': 1.0, 'dropout': 0.5, 'embedding_dim': 300, 'epochs': 20, 'hidden_dim': 64, 'learning_rate': 0.001, 'patience': 3, 'use_attention': True, 'weight_decay': 1e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.0935921438105471, Validation Loss: 1.0842567341668266\n",
            "Epoch 2, Training Loss: 1.0809943128276516, Validation Loss: 1.072224144424711\n",
            "Epoch 3, Training Loss: 1.0722329611176844, Validation Loss: 1.0618783576147897\n",
            "Epoch 4, Training Loss: 1.0611881621786066, Validation Loss: 1.0527629085949488\n",
            "Epoch 5, Training Loss: 1.0547346453945916, Validation Loss: 1.0446805996554238\n",
            "Epoch 6, Training Loss: 1.0465484774327494, Validation Loss: 1.037360823580197\n",
            "Epoch 7, Training Loss: 1.0404550575458251, Validation Loss: 1.0306607165506907\n",
            "Epoch 8, Training Loss: 1.034580494100983, Validation Loss: 1.0243898864303316\n",
            "Epoch 9, Training Loss: 1.028318320577209, Validation Loss: 1.0185109653643198\n",
            "Epoch 10, Training Loss: 1.0219221351382968, Validation Loss: 1.0129391316856657\n",
            "Epoch 11, Training Loss: 1.0180746604193438, Validation Loss: 1.0076575108936854\n",
            "Epoch 12, Training Loss: 1.0132022352368981, Validation Loss: 1.0026557339089257\n",
            "Epoch 13, Training Loss: 1.0102173092665974, Validation Loss: 0.9979177649532046\n",
            "Epoch 14, Training Loss: 1.0061380557111792, Validation Loss: 0.9934159794024059\n",
            "Epoch 15, Training Loss: 1.0018850954266283, Validation Loss: 0.9891621257577624\n",
            "Epoch 16, Training Loss: 0.9974173071148159, Validation Loss: 0.9851023150341851\n",
            "Epoch 17, Training Loss: 0.9943542598604082, Validation Loss: 0.9812211117574147\n",
            "Epoch 18, Training Loss: 0.9920631840422347, Validation Loss: 0.9775659378085818\n",
            "Epoch 19, Training Loss: 0.987096358258445, Validation Loss: 0.9740417706114906\n",
            "Epoch 20, Training Loss: 0.9850307660059886, Validation Loss: 0.970756300858089\n",
            "Validation Accuracy: 0.5765765765765766\n",
            "Training with params: {'clip_value': 1.0, 'dropout': 0.5, 'embedding_dim': 300, 'epochs': 20, 'hidden_dim': 64, 'learning_rate': 0.001, 'patience': 5, 'use_attention': True, 'weight_decay': 0.0001}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.097758020903613, Validation Loss: 1.0872155002185278\n",
            "Epoch 2, Training Loss: 1.0806957467182263, Validation Loss: 1.0702919363975525\n",
            "Epoch 3, Training Loss: 1.066439860575908, Validation Loss: 1.0558571134294783\n",
            "Epoch 4, Training Loss: 1.053678246768745, Validation Loss: 1.0432978315012795\n",
            "Epoch 5, Training Loss: 1.0436397283463865, Validation Loss: 1.032200357743672\n",
            "Epoch 6, Training Loss: 1.0339376770698272, Validation Loss: 1.0223458877631597\n",
            "Epoch 7, Training Loss: 1.0243727336595725, Validation Loss: 1.0134827877793993\n",
            "Epoch 8, Training Loss: 1.0163916722611264, Validation Loss: 1.0054771027394704\n",
            "Epoch 9, Training Loss: 1.010467093807083, Validation Loss: 0.998335525393486\n",
            "Epoch 10, Training Loss: 1.0033621095322274, Validation Loss: 0.9918157692466464\n",
            "Epoch 11, Training Loss: 0.9969875825954987, Validation Loss: 0.9859700351953506\n",
            "Epoch 12, Training Loss: 0.9915526179043023, Validation Loss: 0.980614538703646\n",
            "Epoch 13, Training Loss: 0.9883384181035532, Validation Loss: 0.975775916661535\n",
            "Epoch 14, Training Loss: 0.9840946788186425, Validation Loss: 0.9714501180819103\n",
            "Epoch 15, Training Loss: 0.9816645185152689, Validation Loss: 0.9675916475909097\n",
            "Epoch 16, Training Loss: 0.9768866730165912, Validation Loss: 0.9640649684837886\n",
            "Epoch 17, Training Loss: 0.9734965302385725, Validation Loss: 0.9609233502830777\n",
            "Epoch 18, Training Loss: 0.9721818107205469, Validation Loss: 0.9580680536372321\n",
            "Epoch 19, Training Loss: 0.9684653051264651, Validation Loss: 0.9555355246577945\n",
            "Epoch 20, Training Loss: 0.9660536781087652, Validation Loss: 0.9532653795821326\n",
            "Validation Accuracy: 0.588963963963964\n",
            "Training with params: {'clip_value': 1.0, 'dropout': 0.5, 'embedding_dim': 300, 'epochs': 20, 'hidden_dim': 64, 'learning_rate': 0.001, 'patience': 5, 'use_attention': True, 'weight_decay': 1e-05}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.09077861448666, Validation Loss: 1.084112218448094\n",
            "Epoch 2, Training Loss: 1.0816174375044334, Validation Loss: 1.0756773693220956\n",
            "Epoch 3, Training Loss: 1.0748010336815774, Validation Loss: 1.0685618264334542\n",
            "Epoch 4, Training Loss: 1.069659920157613, Validation Loss: 1.062463436807905\n",
            "Epoch 5, Training Loss: 1.0641005766821336, Validation Loss: 1.0571482479572296\n",
            "Epoch 6, Training Loss: 1.0602270874891195, Validation Loss: 1.0523325034550257\n",
            "Epoch 7, Training Loss: 1.0556700098084975, Validation Loss: 1.0478998678071159\n",
            "Epoch 8, Training Loss: 1.0518337458640605, Validation Loss: 1.043788228716169\n",
            "Epoch 9, Training Loss: 1.0475762244817373, Validation Loss: 1.0398963689804077\n",
            "Epoch 10, Training Loss: 1.0439813053822733, Validation Loss: 1.0361800342798233\n",
            "Epoch 11, Training Loss: 1.039935918541642, Validation Loss: 1.0325974098273687\n",
            "Epoch 12, Training Loss: 1.0378621556200422, Validation Loss: 1.0291355209691184\n",
            "Epoch 13, Training Loss: 1.0355276196926564, Validation Loss: 1.0258208747420992\n",
            "Epoch 14, Training Loss: 1.0310886631140839, Validation Loss: 1.0225388365132468\n",
            "Epoch 15, Training Loss: 1.0283403812765002, Validation Loss: 1.0192942470312119\n",
            "Epoch 16, Training Loss: 1.0267730317674242, Validation Loss: 1.016165173479489\n",
            "Epoch 17, Training Loss: 1.0229486484785337, Validation Loss: 1.0130885222128458\n",
            "Epoch 18, Training Loss: 1.0201130020725835, Validation Loss: 1.0100858530827932\n",
            "Epoch 19, Training Loss: 1.0177837325645998, Validation Loss: 1.0071082966668266\n",
            "Epoch 20, Training Loss: 1.0146464267829518, Validation Loss: 1.004132051553045\n",
            "Validation Accuracy: 0.5574324324324325\n",
            "Training with params: {'clip_value': 1.0, 'dropout': 0.5, 'embedding_dim': 300, 'epochs': 20, 'hidden_dim': 64, 'learning_rate': 0.01, 'patience': 3, 'use_attention': True, 'weight_decay': 0.0001}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 1.081431973087895, Validation Loss: 1.0510128566196986\n",
            "Epoch 2, Training Loss: 1.0453756537523355, Validation Loss: 1.0239662847348623\n",
            "Epoch 3, Training Loss: 1.0247799013112042, Validation Loss: 1.001575265611921\n",
            "Epoch 4, Training Loss: 1.0056907083537128, Validation Loss: 0.9802202561071941\n",
            "Epoch 5, Training Loss: 0.9880425272224186, Validation Loss: 0.9604417915855136\n",
            "Epoch 6, Training Loss: 0.971729093038284, Validation Loss: 0.9439303087336677\n",
            "Epoch 7, Training Loss: 0.958810115182722, Validation Loss: 0.9318684403385434\n",
            "Epoch 8, Training Loss: 0.9479313479350494, Validation Loss: 0.9220819984163556\n",
            "Epoch 9, Training Loss: 0.9421603003063718, Validation Loss: 0.9144133010080883\n",
            "Epoch 10, Training Loss: 0.9367119165154191, Validation Loss: 0.9111763430493218\n",
            "Epoch 11, Training Loss: 0.9316138002249572, Validation Loss: 0.9084150046110153\n",
            "Epoch 12, Training Loss: 0.9292850005734075, Validation Loss: 0.9056028553417751\n",
            "Epoch 13, Training Loss: 0.9284213166516107, Validation Loss: 0.9046774485281536\n",
            "Epoch 14, Training Loss: 0.9275219351858706, Validation Loss: 0.9037574997970036\n",
            "Epoch 15, Training Loss: 0.9246068210215181, Validation Loss: 0.9018951186111995\n",
            "Epoch 16, Training Loss: 0.9234037804710973, Validation Loss: 0.9018483523811612\n",
            "Epoch 17, Training Loss: 0.923612860945968, Validation Loss: 0.9002476419721331\n",
            "Epoch 18, Training Loss: 0.9226828102055971, Validation Loss: 0.9005202544586999\n",
            "Epoch 19, Training Loss: 0.9218359159993695, Validation Loss: 0.8989397606679371\n",
            "Epoch 20, Training Loss: 0.9199444460976232, Validation Loss: 0.8989304091249194\n",
            "Validation Accuracy: 0.5990990990990991\n",
            "Training with params: {'clip_value': 1.0, 'dropout': 0.5, 'embedding_dim': 300, 'epochs': 20, 'hidden_dim': 64, 'learning_rate': 0.01, 'patience': 3, 'use_attention': True, 'weight_decay': 1e-05}\n",
            "Epoch 1, Training Loss: 1.053870171577007, Validation Loss: 1.011680224112102\n",
            "Epoch 2, Training Loss: 0.9974907585629472, Validation Loss: 0.9714683273008892\n",
            "Epoch 3, Training Loss: 0.9743729574723287, Validation Loss: 0.9538499861955643\n",
            "Epoch 4, Training Loss: 0.9640062360076217, Validation Loss: 0.9455940638269696\n",
            "Epoch 5, Training Loss: 0.9592577713029878, Validation Loss: 0.9399443800960269\n",
            "Epoch 6, Training Loss: 0.9572544151598269, Validation Loss: 0.9347413522856576\n",
            "Epoch 7, Training Loss: 0.9514668084479667, Validation Loss: 0.9302806769098554\n",
            "Epoch 8, Training Loss: 0.9493058595034454, Validation Loss: 0.9263727430786405\n",
            "Epoch 9, Training Loss: 0.9468367046064085, Validation Loss: 0.9233181795903614\n",
            "Epoch 10, Training Loss: 0.9442718241128836, Validation Loss: 0.9201955454690116\n",
            "Epoch 11, Training Loss: 0.9422514162085078, Validation Loss: 0.9177906598363604\n",
            "Epoch 12, Training Loss: 0.9388703620648599, Validation Loss: 0.9155273948396955\n",
            "Epoch 13, Training Loss: 0.9383104494563094, Validation Loss: 0.9130272652421679\n",
            "Epoch 14, Training Loss: 0.9363930373041479, Validation Loss: 0.9114825299807957\n",
            "Epoch 15, Training Loss: 0.9318740394738343, Validation Loss: 0.9092012026480266\n",
            "Epoch 16, Training Loss: 0.9333650144907806, Validation Loss: 0.907660961151123\n",
            "Epoch 17, Training Loss: 0.9308057754963368, Validation Loss: 0.9062074082238334\n",
            "Epoch 18, Training Loss: 0.9283270736535391, Validation Loss: 0.9051189912217004\n",
            "Epoch 19, Training Loss: 0.9270136444955259, Validation Loss: 0.9039412992341178\n",
            "Epoch 20, Training Loss: 0.9257378081480662, Validation Loss: 0.9030259060008186\n",
            "Validation Accuracy: 0.5990990990990991\n",
            "Training with params: {'clip_value': 1.0, 'dropout': 0.5, 'embedding_dim': 300, 'epochs': 20, 'hidden_dim': 64, 'learning_rate': 0.01, 'patience': 5, 'use_attention': True, 'weight_decay': 0.0001}\n",
            "Epoch 1, Training Loss: 1.066832827018188, Validation Loss: 1.0228440995727266\n",
            "Epoch 2, Training Loss: 1.013051828017106, Validation Loss: 0.9793026894330978\n",
            "Epoch 3, Training Loss: 0.9888222494103887, Validation Loss: 0.9563652000256947\n",
            "Epoch 4, Training Loss: 0.9763486651149956, Validation Loss: 0.9435153518404279\n",
            "Epoch 5, Training Loss: 0.9691471779668653, Validation Loss: 0.9342915160315377\n",
            "Epoch 6, Training Loss: 0.9623290638665896, Validation Loss: 0.9277672086443219\n",
            "Epoch 7, Training Loss: 0.9585948111237707, Validation Loss: 0.9222244322299957\n",
            "Epoch 8, Training Loss: 0.9507473411860766, Validation Loss: 0.9169487527438572\n",
            "Epoch 9, Training Loss: 0.9507447102585355, Validation Loss: 0.9133332754884448\n",
            "Epoch 10, Training Loss: 0.9445864547480334, Validation Loss: 0.9110119236367089\n",
            "Epoch 11, Training Loss: 0.942281620728003, Validation Loss: 0.9085995533636638\n",
            "Epoch 12, Training Loss: 0.9398505209802507, Validation Loss: 0.9064212696892875\n",
            "Epoch 13, Training Loss: 0.9389481259895874, Validation Loss: 0.9045111238956451\n",
            "Epoch 14, Training Loss: 0.9352198506260777, Validation Loss: 0.9028029548270362\n",
            "Epoch 15, Training Loss: 0.9328968549096907, Validation Loss: 0.9018396820340838\n",
            "Epoch 16, Training Loss: 0.9312718352219006, Validation Loss: 0.9012202492782048\n",
            "Epoch 17, Training Loss: 0.9322000258677715, Validation Loss: 0.9000213891267776\n",
            "Epoch 18, Training Loss: 0.9303921332230439, Validation Loss: 0.8997961729764938\n",
            "Epoch 19, Training Loss: 0.9299072894427154, Validation Loss: 0.8994647307055337\n",
            "Epoch 20, Training Loss: 0.9291715463539502, Validation Loss: 0.8985684939793178\n",
            "Validation Accuracy: 0.5990990990990991\n",
            "Training with params: {'clip_value': 1.0, 'dropout': 0.5, 'embedding_dim': 300, 'epochs': 20, 'hidden_dim': 64, 'learning_rate': 0.01, 'patience': 5, 'use_attention': True, 'weight_decay': 1e-05}\n",
            "Epoch 1, Training Loss: 1.066101136776778, Validation Loss: 1.0417936593294144\n",
            "Epoch 2, Training Loss: 1.0332474883075233, Validation Loss: 1.011651173233986\n",
            "Epoch 3, Training Loss: 1.0107254963200372, Validation Loss: 0.9850857193980899\n",
            "Epoch 4, Training Loss: 0.9890645602801899, Validation Loss: 0.962715534227235\n",
            "Epoch 5, Training Loss: 0.9769220148120914, Validation Loss: 0.946886556489127\n",
            "Epoch 6, Training Loss: 0.9661375568793701, Validation Loss: 0.9351344853639603\n",
            "Epoch 7, Training Loss: 0.9589209564634271, Validation Loss: 0.9284863663571221\n",
            "Epoch 8, Training Loss: 0.9556429662682988, Validation Loss: 0.9220445113522666\n",
            "Epoch 9, Training Loss: 0.9499201677940987, Validation Loss: 0.9180773709501538\n",
            "Epoch 10, Training Loss: 0.9468492878986908, Validation Loss: 0.9140553772449493\n",
            "Epoch 11, Training Loss: 0.94437702282055, Validation Loss: 0.9115687353270394\n",
            "Epoch 12, Training Loss: 0.940568885287723, Validation Loss: 0.9088541482176099\n",
            "Epoch 13, Training Loss: 0.938950579177152, Validation Loss: 0.9073083656174796\n",
            "Epoch 14, Training Loss: 0.9359638387555475, Validation Loss: 0.9056820528847831\n",
            "Epoch 15, Training Loss: 0.9357468692569045, Validation Loss: 0.9046836176088878\n",
            "Epoch 16, Training Loss: 0.9320826229748426, Validation Loss: 0.9044235348701477\n",
            "Epoch 17, Training Loss: 0.9347899067509282, Validation Loss: 0.9024247782570975\n",
            "Epoch 18, Training Loss: 0.9305473211649302, Validation Loss: 0.9017862358263561\n",
            "Epoch 19, Training Loss: 0.9307936891779169, Validation Loss: 0.9008779994079045\n",
            "Epoch 20, Training Loss: 0.9294291748119904, Validation Loss: 0.8996338269540242\n",
            "Validation Accuracy: 0.5990990990990991\n",
            "Best params: {'clip_value': 1.0, 'dropout': 0.5, 'embedding_dim': 300, 'epochs': 10, 'hidden_dim': 64, 'learning_rate': 0.01, 'patience': 3, 'use_attention': True, 'weight_decay': 0.0001}, Best Validation Accuracy: 0.5990990990990991\n",
            "Epoch 1, Training Loss: 1.0369495663556967, Validation Loss: 0.9886226419891629\n",
            "Epoch 2, Training Loss: 0.9831977679922774, Validation Loss: 0.9511599285261971\n",
            "Epoch 3, Training Loss: 0.9626722306281597, Validation Loss: 0.9358331624950681\n",
            "Epoch 4, Training Loss: 0.9524533319043683, Validation Loss: 0.9281480354922158\n",
            "Epoch 5, Training Loss: 0.9480513914211376, Validation Loss: 0.9234293720551899\n",
            "Epoch 6, Training Loss: 0.9455481891159538, Validation Loss: 0.9194578038794654\n",
            "Epoch 7, Training Loss: 0.9411025192286517, Validation Loss: 0.9176936000585556\n",
            "Epoch 8, Training Loss: 0.9397803907458847, Validation Loss: 0.9154235678059714\n",
            "Epoch 9, Training Loss: 0.9346835586401794, Validation Loss: 0.9147466612713677\n",
            "Epoch 10, Training Loss: 0.9349562901634354, Validation Loss: 0.9119944806609835\n",
            "Final Validation Accuracy: 0.588963963963964\n",
            "Final Validation Precision: 0.42976224456978585\n",
            "Final Validation Recall: 0.588963963963964\n",
            "Final Validation Confusion Matrix:\n",
            "[[  0  80 161]\n",
            " [  0 170  89]\n",
            " [  0  35 353]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy: 0.5937846836847946\n",
            "Final Test Precision: 0.4324379456039457\n",
            "Final Test Recall: 0.5937846836847946\n",
            "Final Test Confusion Matrix:\n",
            "[[  0  89 156]\n",
            " [  0 166  97]\n",
            " [  0  24 369]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.Testing and Evaluation**"
      ],
      "metadata": {
        "id": "knOJ8HeMY36F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Output**"
      ],
      "metadata": {
        "id": "elHjdFkDlh7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pik55NxGCcEq",
        "outputId": "e634b0ad-d908-4cba-a3d7-9bacce30d2b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(8659, 300)\n",
              "  (aspect_embedding): Embedding(8, 8)\n",
              "  (lstm): LSTM(308, 64, batch_first=True, bidirectional=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
              "  (attention): Linear(in_features=136, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "torch.save(final_model.state_dict(), 'path_to_final_model.pth')\n",
        "\n",
        "print(\"Model weights have been saved to 'path_to_final_model.pth'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Qz-7b8LIN8m",
        "outputId": "a70bf931-7259-43e5-aeb5-a146995079b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model weights have been saved to 'path_to_final_model.pth'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change model to evaluation mode\n",
        "model = LSTMModel(len(vocab), 300, 64, 3, len(aspect_to_idx), use_attention=True,return_attention = True, dropout=0.5, embedding_matrix=embedding_matrix)\n",
        "model.load_state_dict(torch.load('path_to_final_model.pth'))\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOYAztMz1mYm",
        "outputId": "5b21f109-e697-4da4-9bed-5a7ab9ee5a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(8659, 300)\n",
              "  (aspect_embedding): Embedding(8, 8)\n",
              "  (lstm): LSTM(308, 64, batch_first=True, bidirectional=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
              "  (attention): Linear(in_features=136, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = LSTMModel(vocab_size, embedding_dim, hidden_dim, output_dim, aspect_dim, use_attention=True, return_attention=True, dropout=0.5, embedding_matrix=embedding_matrix)\n",
        "model1.load_state_dict(torch.load('path_to_final_model_GloVe.pth'))\n",
        "model1.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvvN6K086rLu",
        "outputId": "a00d38bf-fff1-420f-f5fa-a0056ca8f98b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMModel(\n",
              "  (embedding): Embedding(8659, 300)\n",
              "  (aspect_embedding): Embedding(8, 8)\n",
              "  (lstm): LSTM(308, 64, batch_first=True, bidirectional=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
              "  (attention): Linear(in_features=136, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model represent and attention value outuput**"
      ],
      "metadata": {
        "id": "dJkW_lDulpQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_single_input(input_text, input_aspect, word_to_idx, aspect_to_idx):\n",
        "    tokens = word_tokenize(input_text)\n",
        "    indexed_tokens = [word_to_idx.get(token, 0) for token in tokens]\n",
        "    tensor_input = torch.tensor([indexed_tokens], dtype=torch.long)\n",
        "\n",
        "    # returning a default value of 0\n",
        "    aspect_index = torch.tensor([aspect_to_idx.get(input_aspect, 0)], dtype=torch.long)\n",
        "\n",
        "    return tensor_input, aspect_index, tokens\n",
        "\n",
        "def find_aspect_positions(input_text, aspects):\n",
        "    # convert text to lowercase and split\n",
        "    tokens = word_tokenize(input_text.lower())\n",
        "    positions = {}\n",
        "\n",
        "    for aspect in aspects:\n",
        "        try:\n",
        "            # find aspect in input_text\n",
        "            aspect_index = tokens.index(aspect.lower())\n",
        "            positions[aspect] = aspect_index\n",
        "        except ValueError:\n",
        "            positions[aspect] = -1  # if not in, return -1\n",
        "\n",
        "    return positions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def decode_output(output_and_attention):\n",
        "    output, attention_weights = output_and_attention\n",
        "    _, predicted_indices = torch.max(output, dim=1)\n",
        "    idx_to_sentiment = {0: 'positive', 1: 'negative', 2: 'neutral'}\n",
        "    predicted_sentiments = [idx_to_sentiment[idx.item()] for idx in predicted_indices]\n",
        "    attention_weights = attention_weights.squeeze(0).detach().numpy()\n",
        "\n",
        "    # normalised attention weight\n",
        "    min_weight = np.min(attention_weights)\n",
        "    max_weight = np.max(attention_weights)\n",
        "    normalized_weights = (attention_weights - min_weight) / (max_weight - min_weight)\n",
        "\n",
        "    # Rescaling the normalised weights to a wider range\n",
        "    enhanced_attention_weights = normalized_weights * 100\n",
        "\n",
        "    predicted_sentiments = ['negative' if weight <= 20 else 'positive' if weight <= 80 else 'neutral' for weight in enhanced_attention_weights]\n",
        "\n",
        "    return predicted_sentiments, enhanced_attention_weights\n",
        "\n",
        "\n",
        "\n",
        "def analyze_sentiment(input_text, aspects):\n",
        "    all_results = []\n",
        "    for aspect in aspects:\n",
        "        processed_input, aspect_index, tokens = preprocess_single_input(input_text, aspect, word_to_idx, aspect_to_idx)\n",
        "        output_and_attention = model1(processed_input, aspect_index)\n",
        "        result, attention_weights = decode_output(output_and_attention)\n",
        "        #print(f\"Result for '{aspect}': {result}\")\n",
        "        all_results.append(result)\n",
        "        position = find_aspect_positions(input_text, aspects)[aspect]\n",
        "        specific_aspect = all_results[0][position]\n",
        "        print(f\"Result for '{aspect}': {specific_aspect}\")\n",
        "\n",
        "\n",
        "\n",
        "    # visualisation of attention value\n",
        "    if attention_weights is not None:\n",
        "        # make sure attention weight is 1d\n",
        "        if attention_weights.ndim > 1:\n",
        "            attention_weights = attention_weights.squeeze()  # remove other dimension\n",
        "        if attention_weights.ndim == 1:\n",
        "            plt.figure(figsize=(10, 10))\n",
        "            plt.bar(tokens, attention_weights, alpha=0.7)\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.title(\"Attention Weights per Token\")\n",
        "            plt.xlabel(\"Tokens\")\n",
        "            plt.ylabel(\"Attention Weight\")\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"Attention weights are not properly formatted for visualization.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ilQ6Kmau6a1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"And that is a shame as the restaurant is a pizzeria with a very limited menu outside of pizza\"\n",
        "aspects = [\"restaurant\"]\n",
        "analyze_sentiment(input_text, aspects)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "id": "6pMrgveV7Bvt",
        "outputId": "d630cb14-b39c-490f-b239-accf4ae95fdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for 'restaurant': negative\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"great food but the service was dreadful\"\n",
        "aspects = [\"food\", \"service\"]\n",
        "analyze_sentiment(input_text, aspects)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 944
        },
        "id": "FbkjtOlh7ERy",
        "outputId": "b44a77fe-8bb1-4485-d457-2d4356e8422b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result for 'food': positive\n",
            "Result for 'service': negative\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}